Overview:
The simulation can be run from the "sim_ReachBot_astar.ipynb" notebook. This simulation will display a new plot every time ReachBot takes a step. I haven't been able to find out how to save these plots to a file while running it in Jupyter Notebook. The figure's file name appears correctly in the save folder, but the image is blank. For this reason, I have copied all of the code in the Jupyter Notebook into a Python file "sim_ReachBot_astar_local.py" which I run on my machine locally when I want to save the plotting images. These will automatically save into the "Snapshots" folder. Within the "Snapshots" folder, you can run the script "ReachBot_CreateMovie.py" to create a GIF animation from the individually saved images.

For the A* planning, I repurposed my old code from AA274a Robotic Autonomy. The "utils.py" file is unchanged from how it's provided to students in the course. I did have to make modifications to the starter code in "P1_astar.py", such as adding the obstacle inflation and also passing figure objects in order to make the ReachBot steps and the A* path plot on the same grid. I also fixed what I think was a bug, to now make the paths scale properly if you use the optional "res" parameter. In the end though, I didn't wind up using that feature. I did not have to modify any of the code that was assigned as part of the AA274a assignment. Stephanie: If you were to reuse any parts of the code in "P1_astar.py", you might as well replace my student-written functions (everywhere it says ### Code starts here ###) with those from the assignment's solution manual. My old functions definitely work, but they may not be as robust and some were inefficiently hardcoded in the mindset of "if it works, it works" (the get_neighbors function comes to mind).

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Things Left to Do:
1. A constraint is enforced so that ReachBot cannot place its body or feet inside an obstacle using the astar occupancy grid, but it does not yet check to make sure the line segment connecting the body to a valid foot location is also not cutting through the obstacle. This should be a quick fix, using the same line intersection checks (Bresenham algorithm) that I used for checking line-of-sight to potential subgoals.

2. I used two approximations to determine if the tension constraint is being met for ReachBot. This isn't super robust, and should be replaced with a better model that takes into account more of the physical dynamics of the robot.

3. The greedy actions have occasional issues where the robot will have boxed itself in with its own legs and get stuck, especially when it ends up crawling near the edge of an
obstacle or the boundary of the grid world. In order to make this method more robust, it should have a recovery routine that untangles the legs before resuming to the gait process. This is briefly touched upon in the documentation for calling the solve_subproblem() function in the sim_ReachBot_astar.ipynb notebook. I believe that often the robot could become unstuck by relocating even just the forward-most leg.

4. For now, Iâ€™ve set each subgoal configuration to have an arrangement of feet closely surrounding the body, the same as I have used for the initial configuration and final goal configuration. To make this greedy heuristic more optimal, the algorithm should tailor the position of the feet around each subgoal separately, in order to smooth out the previous subpath with the next subpath as seamlessly as possible.  
